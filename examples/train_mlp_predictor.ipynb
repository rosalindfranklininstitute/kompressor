{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from functools import partial\n",
    "import imageio\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import haiku as hk\n",
    "import optax\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import kompressor as kom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "### Load example image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "image = imageio.imread('data/building.jpg')\n",
    "image = (skimage.transform.resize(image, (1024, 1024)) * 256.).astype(np.uint8)\n",
    "\n",
    "plt.figure(figsize=(4,4), facecolor='w')\n",
    "plt.title('original image')\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "original_highres = jnp.array([image])\n",
    "print(original_highres.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the number of resolutions to train the model over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "### Select neighbourhood size for prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "padding = 1\n",
    "\n",
    "# At padding=0 use neighbours [A-D] to predict values [0-4]\n",
    "\n",
    "# AB    A2B\n",
    "# CD    041\n",
    "#       C3D\n",
    "\n",
    "# At padding=1 use neighbours [A-P] to predict values [0-4]\n",
    "\n",
    "# ABCD    A.B.C.D\n",
    "# EFGH    .......\n",
    "# IJKL    E.F2G.H\n",
    "# MNOP    ..041..\n",
    "#         I.J3K.L\n",
    "#         .......\n",
    "#         M.N.O.P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a simple prediction model based on an MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def MLPEncoder(padding, convolutional=False):\n",
    "\n",
    "    def net_fn(lowres):\n",
    "\n",
    "        # Extract data dimensions\n",
    "        P, C = 5, 3\n",
    "\n",
    "        # Fix kernel size to 1x1 to lock receptive field from growing\n",
    "        K = 1\n",
    "        \n",
    "        # Standard LeNet-300-100 MLP network, parallelized over 2D feature maps\n",
    "\n",
    "        # Extract the features for each neighborhood\n",
    "        if convolutional:\n",
    "            # Extract features from the raw RGB image batch using an even width kernel convolution\n",
    "            features = jax.nn.relu(hk.Conv2D(300, ((padding + 1) * 2), padding='VALID')(lowres))\n",
    "            H, W = features.shape[1:3]\n",
    "        else:\n",
    "            # Extract features from the raw RGB image batch using slicing and stacking followed by a 1x1 kernel convolution\n",
    "            features = kom.image.features_from_lowres(lowres, padding)\n",
    "            H, W = features.shape[1:3]\n",
    "            features = jax.nn.relu(hk.Conv2D(300, K)(hk.Reshape((H, W, -1))(features)))\n",
    "\n",
    "        # features.shape == (B, H, W, N*C)\n",
    "        # where N = ((padding * 2) + 1) ^ 2 is the number of surrounding neighbours included for this padding value\n",
    "\n",
    "        mlp = hk.Sequential([\n",
    "            # Apply the rest of the network as 1x1 kernel convolutions\n",
    "            hk.Conv2D(100, K), jax.nn.relu,\n",
    "            \n",
    "            # Output predictions for each neighbourhood\n",
    "            hk.Conv2D((P*C), K),\n",
    "            hk.Reshape((H, W, P, C)),\n",
    "            # reshape (B, H, W, P*C) -> (B, H, W, P, C)\n",
    "            # where P = 5, the number of values that need to be predicted for each neighbourhood\n",
    "        ])\n",
    "\n",
    "        # features(B, H, W, N, C) -> predictions(B, H, W, P, C)\n",
    "        return mlp(features)\n",
    "\n",
    "    return net_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvolutionalEncoder(padding):\n",
    "\n",
    "    def net_fn(lowres):\n",
    "\n",
    "        # Extract data dimensions\n",
    "        P, C = 5, 3\n",
    "\n",
    "        # Extract features from the raw RGB image batch using an even width kernel convolution\n",
    "        features = jax.nn.swish(hk.Conv2D(300, 2, padding='VALID')(lowres))\n",
    "        \n",
    "        for _ in range(padding):\n",
    "            # Widen the receptive field up to the padding value using 3x3 convolutions to pool by [-1, +1) pixels with each layer\n",
    "            features = jax.nn.swish(hk.Conv2D(100, 3, padding='VALID')(features))\n",
    "            \n",
    "        # Output predictions for each neighbourhood\n",
    "        features = hk.Conv2D((P*C), 1)(features)\n",
    "        H, W = features.shape[1:3]\n",
    "        return hk.Reshape((H, W, P, C))(features)\n",
    "\n",
    "    return net_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Get a kompressor predictor function for a given network and parameter set that can be passed to encode/decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "encode_fn = kom.mapping.uint8.encode_values\n",
    "decode_fn = kom.mapping.uint8.decode_values\n",
    "\n",
    "def RegressionPredictor(model, params):\n",
    "\n",
    "    # Regression predictor function applies convolutional MLP network\n",
    "    @jax.jit\n",
    "    def predictions_fn(lowres):\n",
    "        # lowres.shape == (B, H, W, C)\n",
    "\n",
    "        # Get predictions for neighbourhoods, first layer of network is a convolutional feature extractor\n",
    "        predictions = model.apply(params, jnp.float32(lowres) / 256.)\n",
    "        # Convert predictions to uint8\n",
    "        predictions = jnp.floor(jnp.clip(predictions, 0, 1) * 256.).astype(lowres.dtype)\n",
    "        # predictions.shape == (B, H, W, P, C)\n",
    "        # where P = 5, the number of values that need to be predicted for each neighbourhood\n",
    "\n",
    "        # Extract the maps from the predictions\n",
    "        maps = kom.image.maps_from_predictions(predictions)\n",
    "        # lrmap, udmap, cmap = maps\n",
    "        return maps\n",
    "\n",
    "    return predictions_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prototype of base-kompressor class for handling holding a model and applying it to multiple resolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kompressor:\n",
    "    \n",
    "    def __init__(self, encode_fn, decode_fn, padding):\n",
    "        self.encode_fn, self.decode_fn = encode_fn, decode_fn\n",
    "        self.padding = padding\n",
    "        \n",
    "    def _predictions_fn(self):\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def encode(self, highres, levels=1, chunk=None, progress_fn=None, debug=False):\n",
    "\n",
    "        assert levels > 0\n",
    "        \n",
    "        predictions_fn = self._predictions_fn()\n",
    "        \n",
    "        maps = list()\n",
    "        for level in range(levels):\n",
    "            \n",
    "            if chunk is None:\n",
    "                lowres, maps_dims = kom.image.encode(predictions_fn, self.encode_fn, highres, padding=self.padding)\n",
    "            else:\n",
    "                lowres, maps_dims = kom.image.encode_chunks(predictions_fn, self.encode_fn, highres, padding=self.padding, chunk=chunk, progress_fn=progress_fn)\n",
    "                \n",
    "            if debug:\n",
    "                maps.append((lowres, maps_dims, highres))\n",
    "            else:\n",
    "                maps.append(maps_dims)\n",
    "                \n",
    "            highres = lowres\n",
    "            \n",
    "        return lowres, maps\n",
    "\n",
    "    def decode(self, lowres, maps, chunk=None, progress_fn=None, debug=False):\n",
    "\n",
    "        assert len(maps) > 0\n",
    "        \n",
    "        predictions_fn = self._predictions_fn()\n",
    "        \n",
    "        for maps_dims in reversed(maps):\n",
    "            \n",
    "            if debug:\n",
    "                _, maps_dims, _ = maps_dims\n",
    "            \n",
    "            if chunk is None:\n",
    "                highres = kom.image.decode(predictions_fn, self.decode_fn, lowres, maps_dims, padding=self.padding)\n",
    "            else:\n",
    "                highres = kom.image.decode_chunks(predictions_fn, self.decode_fn, lowres, maps_dims, padding=self.padding, chunk=chunk, progress_fn=progress_fn)\n",
    "            \n",
    "            lowres = highres\n",
    "\n",
    "        return highres                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prototype of a Haiku based kompressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HaikuKompressor(Kompressor):\n",
    "    \n",
    "    def __init__(self, encode_fn, decode_fn, padding, model_fn, predictions_fn, seed=None):\n",
    "        super().__init__(encode_fn=encode_fn, decode_fn=decode_fn, padding=padding)\n",
    "        self.model_fn = model_fn\n",
    "        self.__predictions_fn = predictions_fn\n",
    "        self.params = self.avg_params = None\n",
    "        \n",
    "        self.model = hk.without_apply_rng(hk.transform(model_fn(self.padding)))\n",
    "        \n",
    "    def _predictions_fn(self):\n",
    "        return self.__predictions_fn(self.model, self.avg_params)\n",
    "    \n",
    "    def init(self, ds_train, seed=None):\n",
    "        \n",
    "        ds_train = ds_train.as_numpy_iterator()\n",
    "        \n",
    "        if self.params is None:\n",
    "            self.params = self.avg_params = self.model.init(jax.random.PRNGKey(seed or np.random.randint(1e6)), next(ds_train)['lowres'])\n",
    "    \n",
    "        return self\n",
    "    \n",
    "    def fit(self, ds_train, start_step=0, end_step=1, callbacks=None):\n",
    "        \n",
    "        callbacks = callbacks or list()\n",
    "        \n",
    "        assert 0 <= start_step < end_step\n",
    "        \n",
    "        ds_train = ds_train.as_numpy_iterator()\n",
    "        \n",
    "        opt = optax.adam(1e-4)\n",
    "        opt_state = opt.init(self.params)\n",
    "        \n",
    "        @jax.jit\n",
    "        def l2(params):\n",
    "            return 0.5 * sum(jnp.sum(jnp.square(param)) for param in jax.tree_leaves(params))\n",
    "\n",
    "        @jax.jit\n",
    "        def loss(params, batch):\n",
    "            predictions = self.model.apply(params, batch['lowres'])\n",
    "            prediction_loss = jnp.mean(kom.image.losses.mean_squared_error(predictions, batch['targets']))\n",
    "            return prediction_loss + (1e-4 * l2(params))\n",
    "\n",
    "        @jax.jit\n",
    "        def update(params, opt_state, batch):\n",
    "            value, grads = jax.value_and_grad(loss)(params, batch)\n",
    "            updates, opt_state = opt.update(grads, opt_state)\n",
    "            new_params = optax.apply_updates(params, updates)\n",
    "            return value, new_params, opt_state\n",
    "\n",
    "        @jax.jit\n",
    "        def ema_update(params, avg_params):\n",
    "            return optax.incremental_update(params, avg_params, step_size=0.001)\n",
    "        \n",
    "        # Train/eval loop\n",
    "        for step in trange(start_step, end_step, desc='steps'):\n",
    "            \n",
    "            train_batch = next(ds_train)\n",
    "            \n",
    "            for callback in callbacks:\n",
    "                callback.on_step_start(step=step, compressor=self)\n",
    "            \n",
    "            # Update params\n",
    "            loss, self.params, opt_state = update(self.params, opt_state, train_batch)\n",
    "            self.avg_params = ema_update(self.params, self.avg_params)\n",
    "\n",
    "            for callback in callbacks:\n",
    "                callback.on_step_end(step=step, loss=loss, compressor=self)\n",
    "        \n",
    "        # Return self to enable chaining\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prototype of kompressor model training callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Callback:\n",
    "    \n",
    "    def on_step_start(self, *args, **kargs):\n",
    "        pass\n",
    "        \n",
    "    \n",
    "    def on_step_end(self, *args, **kargs):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HaikuMetricsCallback(Callback):\n",
    "    \n",
    "    def __init__(self, log_dir, chunk, ds_train, ds_test=None, log_freq=100, levels=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.log_dir = log_dir\n",
    "        \n",
    "        assert log_freq > 0\n",
    "        self.log_freq = log_freq\n",
    "        \n",
    "        assert levels > 0\n",
    "        self.levels = levels\n",
    "        \n",
    "        self.chunk = chunk\n",
    "        \n",
    "        self.ds_train = ds_train.as_numpy_iterator()\n",
    "        self.ds_test = None if ds_test is None else ds_test.as_numpy_iterator()\n",
    "        self.train_writer = tf.summary.create_file_writer(os.path.join(self.log_dir, 'train'))\n",
    "        self.test_writer  = None if self.ds_test  is None else tf.summary.create_file_writer(os.path.join(self.log_dir, 'test'))\n",
    "        \n",
    "    def on_step_end(self, step, loss, compressor, *args, **kargs):\n",
    "        \n",
    "        if step % self.log_freq != 0:\n",
    "            return\n",
    "        \n",
    "        def log(highres):\n",
    "            \n",
    "            lowres, maps = compressor.encode(highres, levels=self.levels, chunk=self.chunk)\n",
    "            omaps = kom.image.maps_from_highres(highres)\n",
    "\n",
    "            for level, (maps, dims) in enumerate(maps):\n",
    "                for label, m, om in zip(['lrmap', 'udmap', 'cmap'], maps, omaps):\n",
    "\n",
    "                    cm = kom.utils.encode_transform_centre_uint8(m)\n",
    "                    zm = jnp.int32(cm) - 128\n",
    "                    \n",
    "                    tv = jnp.mean(kom.image.losses.mean_total_variation(zm))\n",
    "                    tf.summary.scalar(f'{m.shape[1:]} | {label} | total variation', tv, step=step)\n",
    "\n",
    "                    for k in [1, 8]:\n",
    "                        wk = jnp.mean(kom.image.metrics.within_k(zm, k))\n",
    "                        tf.summary.scalar(f'{m.shape[1:]} | {label} | within k={k}', wk, step=step)\n",
    "\n",
    "                    opng_bpp = kom.image.metrics.imageio_rgb_bpp(om, format='png')\n",
    "                    png_bpp = kom.image.metrics.imageio_rgb_bpp(m, format='png')\n",
    "                    tf.summary.scalar(f'{m.shape[1:]} | {label} | png bpp', jnp.mean(png_bpp), step=step)\n",
    "                    tf.summary.scalar(f'{m.shape[1:]} | {label} | png ratio', jnp.mean(png_bpp / opng_bpp), step=step)\n",
    "                    \n",
    "        @jax.jit\n",
    "        def l2(params):\n",
    "            return 0.5 * sum(jnp.sum(jnp.square(param)) for param in jax.tree_leaves(params))\n",
    "                    \n",
    "        with self.train_writer.as_default(): \n",
    "\n",
    "            tf.summary.scalar('loss', loss, step=step)\n",
    "            tf.summary.scalar('l2', l2(compressor.params), step=step)\n",
    "            log(next(self.ds_train))\n",
    "                \n",
    "        if self.ds_test is not None:\n",
    "            with self.test_writer.as_default(): \n",
    "                \n",
    "                tf.summary.scalar('l2', l2(compressor.avg_params), step=step)\n",
    "                log(next(self.ds_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the encoded maps for a single level of compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_maps(title, highres, lowres, maps):\n",
    "\n",
    "    ks = [1, 8, 64]\n",
    "    \n",
    "    fig, ax = plt.subplots(4, 7 + (3 * len(ks)), figsize=(36, 10), facecolor='w')\n",
    "\n",
    "    plt.suptitle(title)\n",
    "\n",
    "    plt.sca(ax[0, 0])\n",
    "    plt.title(f'highres {highres[0].shape}')\n",
    "    plt.axis('off')\n",
    "    plt.axis('equal')\n",
    "    plt.imshow(highres[0])\n",
    "\n",
    "    plt.sca(ax[1, 0])\n",
    "    plt.title(f'lowres {lowres[0].shape}')\n",
    "    plt.axis('off')\n",
    "    plt.axis('equal')\n",
    "    plt.imshow(lowres[0])\n",
    "\n",
    "    plt.sca(ax[2, 0])\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.sca(ax[3, 0])\n",
    "    plt.axis('off')\n",
    "    \n",
    "    bins = np.arange(257)\n",
    "    for midx, (label, m) in enumerate(zip(['lrmap', 'udmap', 'cmap'], maps)):\n",
    "\n",
    "        im = kom.utils.encode_transform_interleaved_uint8(m)\n",
    "        cm = jnp.int32(kom.utils.encode_transform_centre_uint8(m)) - 128\n",
    "        \n",
    "        plt.sca(ax[0, (midx*(2+len(ks)))+1])\n",
    "        plt.title(f'{label} {m[0].shape}')\n",
    "        sns.despine(ax=plt.gca())\n",
    "        for cidx, colour in reversed(list(enumerate('rgb'))):\n",
    "            plt.hist(np.array(m[0, ..., cidx]).flatten(), bins=bins, color=colour, alpha=0.25, histtype='step', density=True)\n",
    "            \n",
    "        plt.sca(ax[0, (midx*(2+len(ks)))+2])\n",
    "        plt.title(f'{label} centre')\n",
    "        sns.despine(ax=plt.gca())\n",
    "        for cidx, colour in reversed(list(enumerate('rgb'))):\n",
    "            plt.hist(np.array(cm[0, ..., cidx]).flatten(), bins=bins-128, color=colour, alpha=0.25, histtype='step', density=True)\n",
    "        \n",
    "        plt.sca(ax[0, (midx*(2+len(ks)))+3])\n",
    "        plt.title(f'{label} interleave')\n",
    "        sns.despine(ax=plt.gca())\n",
    "        for cidx, colour in reversed(list(enumerate('rgb'))):\n",
    "            plt.hist(np.array(im[0, ..., cidx]).flatten(), bins=bins, color=colour, alpha=0.25, histtype='step', density=True)\n",
    "            \n",
    "        for ki, k in list(enumerate(ks))[1:]:\n",
    "            plt.sca(ax[0, (midx*(2+len(ks)))+3+ki])\n",
    "            plt.axis('off')\n",
    "        \n",
    "        for cidx, cmap in enumerate(['Reds', 'Greens', 'Blues']):\n",
    "\n",
    "            plt.sca(ax[cidx+1, (midx*(2+len(ks)))+1])\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.imshow(im[0, ..., cidx], vmin=0, vmax=256, cmap=cmap)\n",
    "            \n",
    "            if midx == 0:\n",
    "                plt.ylabel(cmap)\n",
    "                \n",
    "            if cidx == 2:\n",
    "                plt.xlabel(f'{label}\\nDelta')\n",
    "            \n",
    "            plt.sca(ax[cidx+1, (midx*(2+len(ks)))+2])\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.imshow(m[0, ..., cidx], vmin=0, vmax=256, cmap='tab10')\n",
    "            \n",
    "            if cidx == 2:\n",
    "                plt.xlabel(f'{label}\\nFalse Colour')\n",
    "                \n",
    "            for ki, k in enumerate(ks):\n",
    "                plt.sca(ax[cidx+1, (midx*(2+len(ks)))+3+ki])\n",
    "                plt.xticks([])\n",
    "                plt.yticks([])\n",
    "                plt.imshow(im[0, ..., cidx] < (k*2))\n",
    "\n",
    "                plt.title(f'{(jnp.sum(im[0, ..., cidx] < (k*2)) / np.prod(im[0, ..., cidx].shape)) * 100:0.1f} %')\n",
    "                \n",
    "                if cidx == 2:\n",
    "                    plt.xlabel(f'{label}\\nWithin k={k}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct some dummy dataset pipelines using tensorflow.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = tf.data.Dataset.from_tensor_slices(original_highres).repeat()\n",
    "ds_train = kom.image.data.random_chunk_dataset(ds_train, padding=padding, chunk=129, chunks_per_sample=16, chunks_shuffle_buffer=512, levels=levels)\n",
    "ds_train = ds_train.batch(32).prefetch(16)\n",
    "\n",
    "ds_eval_train = tf.data.Dataset.from_tensor_slices(original_highres).repeat().batch(1)\n",
    "ds_eval_test  = tf.data.Dataset.from_tensor_slices(original_highres).repeat().batch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a trainable kompressor instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressor = HaikuKompressor(encode_fn=encode_fn, decode_fn=decode_fn, padding=padding, \n",
    "                             model_fn=ConvolutionalEncoder, predictions_fn=RegressionPredictor).init(ds_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the untrained kompressor to the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "encoded_lowres, encoded_maps = compressor.encode(original_highres, levels=levels, debug=True)\n",
    "reconstructed_highres        = compressor.decode(encoded_lowres, encoded_maps, debug=True)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8,4), facecolor='w')\n",
    "\n",
    "plt.suptitle(f'lossless = {np.allclose(original_highres[0], reconstructed_highres[0])}')\n",
    "\n",
    "plt.sca(ax[0])\n",
    "plt.title('original')\n",
    "plt.imshow(original_highres[0])\n",
    "\n",
    "plt.sca(ax[1])\n",
    "plt.title('reconstructed')\n",
    "plt.imshow(reconstructed_highres[0])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "for level, (lowres, (maps, dims), highres) in enumerate(encoded_maps):\n",
    "    plot_maps(f'mean neighbourhood - level {level}', highres, lowres, maps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the kompressor instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    HaikuMetricsCallback(log_dir=os.path.join('logs', datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")), \n",
    "                         chunk=256, ds_train=ds_eval_train, ds_test=ds_eval_test, log_freq=10, levels=1)\n",
    "]\n",
    "\n",
    "compressor.fit(ds_train=ds_train, start_step=0, end_step=21, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the trained kompressor to the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_lowres, encoded_maps = compressor.encode(original_highres, levels=4, debug=True)\n",
    "reconstructed_highres        = compressor.decode(encoded_lowres, encoded_maps, debug=True)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8,4), facecolor='w')\n",
    "\n",
    "plt.suptitle(f'lossless = {np.allclose(original_highres[0], reconstructed_highres[0])}')\n",
    "\n",
    "plt.sca(ax[0])\n",
    "plt.title('original')\n",
    "plt.imshow(original_highres[0])\n",
    "\n",
    "plt.sca(ax[1])\n",
    "plt.title('reconstructed')\n",
    "plt.imshow(reconstructed_highres[0])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "for level, (lowres, (maps, dims), highres) in enumerate(encoded_maps):\n",
    "    plot_maps(f'mean neighbourhood - level {level}', highres, lowres, maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
